{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tailor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create initial DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_df = tailor.load_data()\n",
    "raw_df.article_id = raw_df.article_id.astype(int)\n",
    "df_revenue = raw_df[['article_id', 'time_on_sale', 'revenue']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give an example, the dataframe looks like this ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revenue.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Benchmark Series\n",
    "\n",
    "Now reshape the dataframes into a format which makes it easier to calculate the mean of each time_on_sale value.  The following steps must be done for each  performance measure.  For now, we will just do it for the dataframe with the column 'revenue' (df_revenue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivoted = df_revenue.pivot_table(values='revenue', index='article_id', columns='time_on_sale')\n",
    "df_reshaped = pd.DataFrame(df_pivoted.to_records()) #cast pivot table into DataFrame \n",
    "df_reshaped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, calculate the mean of each column. Therefore, you have the mean for each time_on_sale value. This series can be used as a benchmark series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_benchmark = df_reshaped.mean(axis=0)\n",
    "revenue_benchmark.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop mean of article ids. It makes no sense and we dont need it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_benchmark = revenue_benchmark.drop(revenue_benchmark.index[0])\n",
    "revenue_benchmark.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast series into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revenue_benchmark = pd.DataFrame()\n",
    "df_revenue_benchmark['time_on_sale'] = revenue_benchmark.keys()\n",
    "df_revenue_benchmark['mean_revenue'] = revenue_benchmark.values\n",
    "df_revenue_benchmark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_revenue_benchmark.time_on_sale, df_revenue_benchmark.mean_revenue);\n",
    "plt.xticks(np.arange(0, 181, step=20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate distance to Benchmark Series\n",
    "\n",
    "Merging both DataFrames yields in ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = pd.merge(df_revenue, df_revenue_benchmark, how='left', on='time_on_sale', left_index=False, right_index=True, sort=True, validate='m:1')\n",
    "result = result.reset_index()\n",
    "result = result.drop('index', axis=1)\n",
    "result = result.rename(index=str, columns={'mean_revenue_y':'mean_revenue'})\n",
    "result.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the distance between revenue and mean_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result['distance'] = ((result['revenue'] - result['mean_revenue'])**2)**0.5\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum up all distances to get just one value for similiarity measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.groupby('article_id').sum()\n",
    "result = result.reset_index()\n",
    "result = result.drop(['revenue', 'mean_revenue'], axis=1)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.sort_values('distance', ascending=True)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First evaluation of the similarity measurement\n",
    "\n",
    "Plot the two article with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_distance = result.iloc[0]\n",
    "second_lowest_distance = result.iloc[1]\n",
    "df_revenue_lowest = df_revenue[df_revenue['article_id']==lowest_distance.article_id]\n",
    "df_revenue_second_lowest = df_revenue[df_revenue['article_id']==second_lowest_distance.article_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_revenue_benchmark.time_on_sale, df_revenue_benchmark.mean_revenue, 'b');\n",
    "plt.plot(df_revenue_lowest.time_on_sale, df_revenue_lowest.revenue, 'r')\n",
    "plt.plot(df_revenue_second_lowest.time_on_sale, df_revenue_second_lowest.revenue, 'g')\n",
    "plt.xticks(np.arange(0, 181, step=20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot some articles with similiar distances. To find similiar values, I just had a look at the sorted result dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_one = raw_df[raw_df['article_id']==902792]\n",
    "article_two = raw_df[raw_df['article_id']==901825]\n",
    "\n",
    "plt.plot(article_one['time_on_sale'], article_one['revenue'], 'r');\n",
    "plt.plot(article_two['time_on_sale'], article_two['revenue'], 'b');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_three = raw_df[raw_df['article_id']==900546]\n",
    "article_four = raw_df[raw_df['article_id']==906171]\n",
    "\n",
    "plt.plot(article_three['time_on_sale'], article_three['revenue'], 'r');\n",
    "plt.plot(article_four['time_on_sale'], article_four['revenue'], 'b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tailor",
   "language": "python",
   "name": "tailor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
