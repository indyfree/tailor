{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Autoreload all package before excecuting a call\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "\n",
    "import tailor\n",
    "from tailor.clustering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tailor.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>season</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>Abteilung</th>\n",
       "      <th>WHG</th>\n",
       "      <th>WUG</th>\n",
       "      <th>month</th>\n",
       "      <th>time_on_sale</th>\n",
       "      <th>original_price</th>\n",
       "      <th>sells_price</th>\n",
       "      <th>discount</th>\n",
       "      <th>markdown</th>\n",
       "      <th>article_count</th>\n",
       "      <th>stock_total</th>\n",
       "      <th>avq</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129434</th>\n",
       "      <td>904435</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Hercules Deusoniensis</td>\n",
       "      <td>mittelgrau</td>\n",
       "      <td>Abteilung002</td>\n",
       "      <td>WHG010</td>\n",
       "      <td>WUG035</td>\n",
       "      <td>Jan</td>\n",
       "      <td>19</td>\n",
       "      <td>49.95</td>\n",
       "      <td>46.071667</td>\n",
       "      <td>3.878333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>7625.0</td>\n",
       "      <td>49.412022</td>\n",
       "      <td>198.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163719</th>\n",
       "      <td>905611</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Snotra</td>\n",
       "      <td>schwarz</td>\n",
       "      <td>Abteilung003</td>\n",
       "      <td>WHG016</td>\n",
       "      <td>WUG057</td>\n",
       "      <td>Feb</td>\n",
       "      <td>15</td>\n",
       "      <td>49.95</td>\n",
       "      <td>49.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>945.0</td>\n",
       "      <td>34.920635</td>\n",
       "      <td>49.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94272</th>\n",
       "      <td>903234</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Snotra</td>\n",
       "      <td>hellgrau</td>\n",
       "      <td>Abteilung005</td>\n",
       "      <td>WHG021</td>\n",
       "      <td>WUG072</td>\n",
       "      <td>Jun</td>\n",
       "      <td>15</td>\n",
       "      <td>89.95</td>\n",
       "      <td>56.616667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>258.0</td>\n",
       "      <td>26.098191</td>\n",
       "      <td>96.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244593</th>\n",
       "      <td>908381</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Mercurius Arvernus</td>\n",
       "      <td>hellgrau</td>\n",
       "      <td>Abteilung002</td>\n",
       "      <td>WHG006</td>\n",
       "      <td>WUG015</td>\n",
       "      <td>Aug</td>\n",
       "      <td>24</td>\n",
       "      <td>49.95</td>\n",
       "      <td>49.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>234.0</td>\n",
       "      <td>69.658120</td>\n",
       "      <td>99.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127068</th>\n",
       "      <td>904354</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Mannus</td>\n",
       "      <td>pink</td>\n",
       "      <td>Abteilung004</td>\n",
       "      <td>WHG028</td>\n",
       "      <td>WUG102</td>\n",
       "      <td>Dec</td>\n",
       "      <td>18</td>\n",
       "      <td>12.95</td>\n",
       "      <td>6.920000</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.857143</td>\n",
       "      <td>5628.0</td>\n",
       "      <td>24.253731</td>\n",
       "      <td>144.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47697</th>\n",
       "      <td>901660</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Heimdall</td>\n",
       "      <td>bordeauxrot</td>\n",
       "      <td>Abteilung002</td>\n",
       "      <td>WHG012</td>\n",
       "      <td>WUG045</td>\n",
       "      <td>Dec</td>\n",
       "      <td>14</td>\n",
       "      <td>79.95</td>\n",
       "      <td>41.955000</td>\n",
       "      <td>8.995000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>879.0</td>\n",
       "      <td>10.608646</td>\n",
       "      <td>80.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44063</th>\n",
       "      <td>901532</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Skadi</td>\n",
       "      <td>dunkelbraun</td>\n",
       "      <td>Abteilung004</td>\n",
       "      <td>WHG026</td>\n",
       "      <td>WUG093</td>\n",
       "      <td>Nov</td>\n",
       "      <td>19</td>\n",
       "      <td>12.95</td>\n",
       "      <td>10.713333</td>\n",
       "      <td>2.236667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.166667</td>\n",
       "      <td>6901.0</td>\n",
       "      <td>26.133894</td>\n",
       "      <td>254.071667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145700</th>\n",
       "      <td>905009</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Gautr</td>\n",
       "      <td>beige</td>\n",
       "      <td>Abteilung002</td>\n",
       "      <td>WHG010</td>\n",
       "      <td>WUG034</td>\n",
       "      <td>May</td>\n",
       "      <td>19</td>\n",
       "      <td>49.95</td>\n",
       "      <td>39.903333</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>2712.0</td>\n",
       "      <td>38.956490</td>\n",
       "      <td>345.991667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121162</th>\n",
       "      <td>904155</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Travalaha</td>\n",
       "      <td>schwarz</td>\n",
       "      <td>Abteilung002</td>\n",
       "      <td>WHG015</td>\n",
       "      <td>WUG053</td>\n",
       "      <td>Dec</td>\n",
       "      <td>19</td>\n",
       "      <td>59.95</td>\n",
       "      <td>49.647500</td>\n",
       "      <td>0.302500</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>45.631808</td>\n",
       "      <td>744.292500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195788</th>\n",
       "      <td>906708</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Tyr</td>\n",
       "      <td>mittelgrau</td>\n",
       "      <td>Abteilung007</td>\n",
       "      <td>WHG042</td>\n",
       "      <td>WUG139</td>\n",
       "      <td>Sep</td>\n",
       "      <td>4</td>\n",
       "      <td>64.95</td>\n",
       "      <td>60.812857</td>\n",
       "      <td>4.137143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>9.703696</td>\n",
       "      <td>483.742857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id  season                  brand        color     Abteilung  \\\n",
       "129434     904435    Fall  Hercules Deusoniensis   mittelgrau  Abteilung002   \n",
       "163719     905611    Fall                 Snotra      schwarz  Abteilung003   \n",
       "94272      903234  Winter                 Snotra     hellgrau  Abteilung005   \n",
       "244593     908381  Winter     Mercurius Arvernus     hellgrau  Abteilung002   \n",
       "127068     904354  Summer                 Mannus         pink  Abteilung004   \n",
       "47697      901660    Fall               Heimdall  bordeauxrot  Abteilung002   \n",
       "44063      901532  Summer                  Skadi  dunkelbraun  Abteilung004   \n",
       "145700     905009  Winter                  Gautr        beige  Abteilung002   \n",
       "121162     904155  Summer              Travalaha      schwarz  Abteilung002   \n",
       "195788     906708  Summer                    Tyr   mittelgrau  Abteilung007   \n",
       "\n",
       "           WHG     WUG month  time_on_sale  original_price  sells_price  \\\n",
       "129434  WHG010  WUG035   Jan            19           49.95    46.071667   \n",
       "163719  WHG016  WUG057   Feb            15           49.95    49.950000   \n",
       "94272   WHG021  WUG072   Jun            15           89.95    56.616667   \n",
       "244593  WHG006  WUG015   Aug            24           49.95    49.950000   \n",
       "127068  WHG028  WUG102   Dec            18           12.95     6.920000   \n",
       "47697   WHG012  WUG045   Dec            14           79.95    41.955000   \n",
       "44063   WHG026  WUG093   Nov            19           12.95    10.713333   \n",
       "145700  WHG010  WUG034   May            19           49.95    39.903333   \n",
       "121162  WHG015  WUG053   Dec            19           59.95    49.647500   \n",
       "195788  WHG042  WUG139   Sep             4           64.95    60.812857   \n",
       "\n",
       "        discount   markdown  article_count  stock_total        avq     revenue  \n",
       "129434  3.878333   0.000000       4.333333       7625.0  49.412022  198.540000  \n",
       "163719  0.000000   0.000000       1.000000        945.0  34.920635   49.950000  \n",
       "94272   0.000000  33.333333       1.666667        258.0  26.098191   96.583333  \n",
       "244593  0.000000   0.000000       2.000000        234.0  69.658120   99.900000  \n",
       "127068  3.030000   3.000000      20.857143       5628.0  24.253731  144.350000  \n",
       "47697   8.995000  29.000000       2.000000        879.0  10.608646   80.920000  \n",
       "44063   2.236667   0.000000      24.166667       6901.0  26.133894  254.071667  \n",
       "145700  0.046667  10.000000       8.666667       2712.0  38.956490  345.991667  \n",
       "121162  0.302500  10.000000      15.000000       2295.0  45.631808  744.292500  \n",
       "195788  4.137143   0.000000       8.000000       1403.0   9.703696  483.742857  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluster_size = 50\n",
    "max_cluster_count = 10\n",
    "clustering_feature = 'article_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 55s, sys: 2.09 s, total: 2min 57s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "split_results = cluster.multi_feature_split(data, distance.euclidean, min_cluster_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the available split layers/depth\n",
    "split_results['Clusters'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Abteilung    Abteilung005\n",
       "WHG                WHG021\n",
       "brand           Fimmilena\n",
       "WUG                WUG073\n",
       "season             Spring\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showcasing how to retrieve the cluster feauteres of the first cluster of the fifth layer\n",
    "split_results['Clusters']['5'][0]['Features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results = pd.Series()\n",
    "merge_results['Groups'] = pd.Series()\n",
    "merge_results['Indexes'] = pd.Series()\n",
    "merge_results['DataFrames'] = pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_parent_name(cluster):\n",
    "    '''generates the name of the parent cluster'''\n",
    "    name = cluster['Name']\n",
    "    # remove last character until name is the parent cluster's name\n",
    "    terminate = False\n",
    "    while not terminate:\n",
    "        character = name[-1:]\n",
    "        if ((character == \"_\") or (character == \"\")):\n",
    "            terminate = True\n",
    "        name = name[:-1]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_leaves(split_results):\n",
    "    '''retrieves all the unsplit clusters / the leaves of the split tree'''\n",
    "    leaves = list()\n",
    "    # iterate through all layers of the clustering\n",
    "    for layer in split_results['Clusters'].index:\n",
    "        # add all layer leaves and remove leaf parents\n",
    "        for add_cluster in split_results['Clusters'][layer]:\n",
    "            check_name = get_cluster_parent_name(add_cluster)\n",
    "            # iterate until parent cluster is found then remove it\n",
    "            for index, check_cluster in enumerate(leaves):\n",
    "                if check_cluster['Name'] == check_name:\n",
    "                    # parent cluster found, remove it\n",
    "                    del leaves[index]\n",
    "                    # no more than one parent cluster, therefore exit for loop\n",
    "                    break\n",
    "            leaves.append(add_cluster)\n",
    "    return leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2280\n",
      "CPU times: user 37.6 s, sys: 31.2 ms, total: 37.7 s\n",
      "Wall time: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clusters = get_leaves(split_results)\n",
    "print(len(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_names(clusters, reversed_sort = False):\n",
    "    '''retrieves all names of the given clusters'''\n",
    "    names = list()\n",
    "    for cluster in clusters:\n",
    "        name = cluster['Name']\n",
    "        names.append(name)\n",
    "    # sort by underscore count\n",
    "    names.sort(key = lambda s: s.count(\"_\"), reverse=reversed_sort)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cluster_names(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(targets):\n",
    "    #calculate distance matrix\n",
    "    length = len(targets)\n",
    "    distances = pd.DataFrame(index=range(length),columns=range(length))\n",
    "    for i, a in enumerate(targets):\n",
    "        for k, b in enumerate(reversed(targets)):\n",
    "            j = length - 1 - k\n",
    "            if j <= i:\n",
    "                break\n",
    "            else:\n",
    "                try:\n",
    "                    d = distance.euclidean(a.values,b.values)\n",
    "                    distances[i][j] = d\n",
    "                    distances[j][i] = d\n",
    "                except:\n",
    "                    print(str(i) + \" \" + str(k))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 45s, sys: 2.16 s, total: 10min 47s\n",
      "Wall time: 11min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "length = len(clusters)\n",
    "targets = list()\n",
    "\n",
    "# dress the clusters for better distance performance\n",
    "for i, cluster in enumerate(clusters):\n",
    "    # only select the distance relevant slice of the Dataframe\n",
    "    target = cluster['DataFrame'].groupby(['time_on_sale']).mean()[feature]\n",
    "    if (len(target) < 26):\n",
    "        # fill with 0 until index 25 so all comparison arrays are the same length\n",
    "        # this improves performance dramatically\n",
    "        target = target.reindex(pd.RangeIndex(26)).fillna(0)\n",
    "    targets.append(target)\n",
    "\n",
    "distances = get_distance_matrix(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_index = np.nanargmin(distances[0])\n",
    "min_value = np.nanmin(distances[0])\n",
    "print(str(min_index) + \" \" + str(min_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distances[0][41])\n",
    "print(distances[41][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all(distances):\n",
    "    # get the closest cluster for each cluster\n",
    "    # generates a Series with pointer lists\n",
    "    closest_clusters = pd.Series(index=range(len(distances)), dtype='object')\n",
    "    for i in distances.index:\n",
    "        target_index = np.nanargmin(distances[i]).item()\n",
    "        # only one value now, but we will add values later\n",
    "        closest_clusters[i] = list()\n",
    "        closest_clusters[i].append(target_index)\n",
    "        \n",
    "    cluster_groups = closest_clusters\n",
    "        \n",
    "    # generate initial groups by adding the index to the target\n",
    "    for i, group in cluster_groups.iteritems():\n",
    "        # first value is the initial closest cluster\n",
    "        target = group[0]\n",
    "        cluster_groups[target].append(i)\n",
    "    \n",
    "    # merge until there are only loners and groups with a pointer loop  \n",
    "    # a pointer loop is when two cluster point towards each other, even over multiple cluster between\n",
    "    finished = False \n",
    "    while not finished:\n",
    "        finished = True\n",
    "        \n",
    "        # merge dependencies\n",
    "        for i, group in cluster_groups.iteritems():\n",
    "            # loner check\n",
    "            if len(group) > 1:\n",
    "                # first value is the initial closest cluster\n",
    "                target = group[0]\n",
    "                # rest of the values are pointers added by dependent groups\n",
    "                pointers = group[1:]\n",
    "                try:\n",
    "                    # check whether this is a dependent group without a pointer loop\n",
    "                    if (target not in pointers):\n",
    "                        # still dependent groups left, we need to iterate at least one more time\n",
    "                        finished = False\n",
    "                        # add own index to target\n",
    "                        cluster_groups[target].append(i)\n",
    "                        # sanity check whether looping is required\n",
    "                        if (type(pointers) is list):\n",
    "                            # multiple entries we can loop\n",
    "                            for x in pointers:\n",
    "                                if (x not in cluster_groups[target]):\n",
    "                                    cluster_groups[target].append(x)\n",
    "                        else:\n",
    "                            print(pointers)\n",
    "                            cluster_groups[target].append(pointers[0])\n",
    "                        # dependent group is spent, create loner\n",
    "                        cluster_groups[i] = list()\n",
    "                        cluster_groups[i].append(target)\n",
    "                except:\n",
    "                    print(\"shit's on fire, yo\")\n",
    "                    print(str(i) + \" \" + str(group) + \" \" + str(target) + \" \" + str(pointers))\n",
    "    \n",
    "    # clear loners\n",
    "    for i, group in cluster_groups.iteritems():\n",
    "        if (len(group) <= 1):\n",
    "            target = group[0]\n",
    "            if target in cluster_groups.index:\n",
    "                cluster_groups[target].append(i)\n",
    "                cluster_groups = cluster_groups.drop(i) \n",
    "    \n",
    "    # dress up the group list        \n",
    "    merged_groups = list()\n",
    "    for i, group in cluster_groups.iteritems():\n",
    "        # replace target with own index\n",
    "        temp = group\n",
    "        temp.append(i)\n",
    "        temp = sorted(list(set(temp)))\n",
    "        merged_groups.append(temp)\n",
    "    merged_groups = sorted(merged_groups)\n",
    "    \n",
    "    # merge connected groups and remove duplicates\n",
    "    for i, group_a in enumerate(merged_groups):\n",
    "        for k, group_b in enumerate(merged_groups):\n",
    "            if k is not i:\n",
    "                for x in group_a:\n",
    "                    if x in set(group_b):\n",
    "                        merged_groups[i] = list(set(group_a).union(set(group_b)))\n",
    "                        # both will point to the same list\n",
    "                        merged_groups[k] = merged_groups[i]\n",
    "                        \n",
    "    clean = list()\n",
    "    for group in merged_groups:\n",
    "        sgroup = sorted(group)\n",
    "        if sgroup not in clean:\n",
    "            clean.append(sgroup)\n",
    "    clean = sorted(clean)\n",
    "    \n",
    "    print(len(list(set(list(itertools.chain.from_iterable(clean))))))\n",
    "    print(len(clean))\n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2280\n",
      "362\n"
     ]
    }
   ],
   "source": [
    "grouped_clusters = merge_all(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results['Indexes']['0'] = grouped_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results['Groups']['0'] = list()\n",
    "merge_results['DataFrames']['0'] = list()\n",
    "for i, pointers in enumerate(merge_results['Indexes']['0']):\n",
    "    group = list()\n",
    "    dfs = list()\n",
    "    for pointer in pointers:\n",
    "        cluster = clusters[pointer]\n",
    "        group.append(cluster)\n",
    "        # retrieving the relevant part of the original dataframe since the cluster dataframe has missing columns\n",
    "        query_string = \"\"\n",
    "        # building the query string\n",
    "        # e.g. '(Abteilung == \"Abteilung001\") & (WHG == \"WHG003\")'\n",
    "        for feature, characteristic in cluster['Features'].iteritems():\n",
    "            query_string = query_string + \" & \" + \"(\" + feature + \" == \" + '\"' + characteristic + '\"' + \")\"\n",
    "        # remove first \" & \"\n",
    "        query_string = query_string[3:]\n",
    "        # select the dataframe part\n",
    "        df_temp = data.query(query_string)\n",
    "        dfs.append(df_temp)\n",
    "    merge_results['Groups']['0'].append(group)\n",
    "    # merge the clusters' dataframes to one and add it\n",
    "    merge_results['DataFrames']['0'].append(pd.concat(dfs, sort=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merge_results['DataFrames']['0'][0].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results['Groups']['0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_results['Indexes']['0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_number = 1\n",
    "above_min_size = False\n",
    "clustering_feature = 'article_count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "280\n",
      "362\n",
      "9\n",
      "11\n",
      "148\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "while not above_min_size:\n",
    "    above_min_size = True\n",
    "    # check whether all clusters are above min_cluster_size\n",
    "    too_small = list()\n",
    "    for i, group in enumerate(merge_results['Groups'][str(merge_number - 1)]):\n",
    "        group_size = merge_results['DataFrames'][str(merge_number - 1)][i]['article_id'].nunique()\n",
    "        if group_size < min_cluster_size:\n",
    "            above_min_size = False\n",
    "            too_small.append(i)\n",
    "    print(len(too_small))\n",
    "    \n",
    "    if not above_min_size:\n",
    "        # distance matrix generation\n",
    "        length = len(merge_results['Groups'][str(merge_number - 1)])\n",
    "        targets = list()\n",
    "        # dress the clusters for better distance performance\n",
    "        for i, group in enumerate(merge_results['Groups'][str(merge_number - 1)]):\n",
    "            # only select the distance relevant slice of the Dataframe\n",
    "            target = merge_results['DataFrames'][str(merge_number - 1)][i].groupby(['time_on_sale']).mean()[clustering_feature]\n",
    "            if (len(target) < 26):\n",
    "                # fill with 0 until index 25 so all comparison arrays are the same length\n",
    "                # this improves performance dramatically\n",
    "                target = target.reindex(pd.RangeIndex(26)).fillna(0)\n",
    "            targets.append(target)\n",
    "        distances = get_distance_matrix(targets)\n",
    "        \n",
    "        \n",
    "        # get the closest group for each group that is too small\n",
    "        # generates a Series with pointer lists\n",
    "        closest_groups = pd.Series(index=range(length), dtype='object')\n",
    "        for i in too_small:\n",
    "            target_index = np.nanargmin(distances[i]).item()\n",
    "            # only one value now, but we will add values later\n",
    "            closest_groups[i] = list()\n",
    "            closest_groups[i].append(target_index)\n",
    "        \n",
    "        relevant_groups = closest_groups\n",
    "        relevant_groups = relevant_groups.dropna()\n",
    "        \n",
    "        # generate initial groups by adding the index to the target\n",
    "        for i, group in relevant_groups.iteritems():\n",
    "            if group is not np.nan:\n",
    "                # first value is the initial closest group\n",
    "                target = group[0]\n",
    "                # sanity check\n",
    "                if target in relevant_groups.index:\n",
    "                    relevant_groups[target].append(i)\n",
    "                else:\n",
    "                    # targeting group outside of too_small\n",
    "                    # add own index to own group to not be a loner\n",
    "                    group.append(i)\n",
    "                \n",
    "        # merge until there are only loners and groups with a pointer loop  \n",
    "        # a pointer loop is when two groups point towards each other, even over multiple groups in between\n",
    "        finished = False \n",
    "        while not finished:\n",
    "            finished = True\n",
    "            \n",
    "            # merge dependencies\n",
    "            for i, group in relevant_groups.iteritems():\n",
    "                # ignore loners\n",
    "                if len(group) > 1:\n",
    "                    # first value is the initial closest cluster\n",
    "                    target = group[0]\n",
    "                    # sanity check\n",
    "                    if target in relevant_groups.index:\n",
    "                        # rest of the values are pointers added by dependent groups\n",
    "                        pointers = group[1:]\n",
    "                        try:\n",
    "                            # check whether this is a dependent group without a pointer loop\n",
    "                            if (target not in pointers):\n",
    "                                # still dependent groups left, we need to iterate at least one more time\n",
    "                                finished = False\n",
    "                                # add own index to target\n",
    "                                relevant_groups[target].append(i)\n",
    "                                # sanity check whether looping is required\n",
    "                                if type(pointers) is list:\n",
    "                                    # multiple entries we can loop\n",
    "                                    for x in pointers:\n",
    "                                        if (x not in relevant_groups[target]):\n",
    "                                            relevant_groups[target].append(x)\n",
    "                                else:\n",
    "                                    print(pointers)\n",
    "                                    relevant_groups[target].append(pointers[0])\n",
    "                                # dependent group is spent, create loner\n",
    "                                relevant_groups[i] = list()\n",
    "                                relevant_groups[i].append(target)\n",
    "                        except:\n",
    "                            print(\"shit's on fire, yo\")\n",
    "                            print(str(i) + \" \" + str(group) + \" \" + str(target) + \" \" + str(pointers))\n",
    "        \n",
    "        # clear loners\n",
    "        for i, group in relevant_groups.iteritems():\n",
    "            if (len(group) <= 1):\n",
    "                target = group[0]\n",
    "                if target in relevant_groups.index:\n",
    "                    relevant_groups[target].append(i)\n",
    "                    relevant_groups = relevant_groups.drop(i)         \n",
    "        \n",
    "        # dress up the group list        \n",
    "        sorted_groups = list()\n",
    "        for i, group in relevant_groups.iteritems():\n",
    "            # replace target with own index\n",
    "            temp = group\n",
    "            temp.append(i)\n",
    "            temp = sorted(list(set(temp)))\n",
    "            sorted_groups.append(temp)\n",
    "        sorted_groups = sorted(sorted_groups)\n",
    "        \n",
    "        # merge connected groups and remove duplicates\n",
    "        for i, group_a in enumerate(sorted_groups):\n",
    "            for k, group_b in enumerate(sorted_groups):\n",
    "                if k is not i:\n",
    "                    for x in group_a:\n",
    "                        if x in set(group_b):\n",
    "                            sorted_groups[i] = list(set(group_a).union(set(group_b)))\n",
    "                            # both will point to the same list\n",
    "                            sorted_groups[k] = sorted_groups[i]              \n",
    "        clean = list()\n",
    "        for group in sorted_groups:\n",
    "            sgroup = sorted(group)\n",
    "            if sgroup not in clean:\n",
    "                clean.append(sgroup)\n",
    "        clean = sorted(clean)\n",
    "        \n",
    "        print(len(list(set(list(itertools.chain.from_iterable(clean))))))\n",
    "        \n",
    "        new_groups = pd.Series(index=range(length), dtype='object')\n",
    "        \n",
    "        # initialize with own index\n",
    "        for i in new_groups.index:\n",
    "            if i not in too_small:\n",
    "                new_groups[i] = list()\n",
    "                new_groups[i].append(i)\n",
    "        \n",
    "        # include the newly generated groups\n",
    "        for i, group in enumerate(clean):\n",
    "            found = False\n",
    "            for x in group:\n",
    "                if x not in too_small:\n",
    "                    # found target group that already was big enough\n",
    "                    found = True\n",
    "                    try:\n",
    "                        # merge groups\n",
    "                        temp = list()\n",
    "                        temp.extend(group)\n",
    "                        temp.extend(new_groups[x])\n",
    "                        temp = sorted(list(set(temp)))\n",
    "                        new_groups[x] = temp\n",
    "                    except:\n",
    "                        print(x)\n",
    "                        print(new_groups[x])\n",
    "                        print(group)\n",
    "                    break\n",
    "            if not found:\n",
    "                # add new group only made of merged too_small groups\n",
    "                new_groups[group[0]] = group\n",
    "        \n",
    "        new_groups = new_groups.dropna()\n",
    "        \n",
    "        clean = list()\n",
    "        for i, group in new_groups.iteritems():\n",
    "            sgroup = sorted(group)\n",
    "            if sgroup not in clean:\n",
    "                clean.append(sgroup)\n",
    "        clean = sorted(clean)\n",
    "        \n",
    "        print(len(list(set(list(itertools.chain.from_iterable(clean))))))\n",
    "        \n",
    "        merge_results['Indexes'][str(merge_number)] = clean\n",
    "        merge_results['Groups'][str(merge_number)] = list()\n",
    "        merge_results['DataFrames'][str(merge_number)] = list()\n",
    "        for i, pointers in enumerate(merge_results['Indexes'][str(merge_number)]):\n",
    "            group = list()\n",
    "            dfs = list()\n",
    "            for pointer in pointers:\n",
    "                df_temp = merge_results['DataFrames'][str(merge_number-1)][pointer]\n",
    "                dfs.append(df_temp)\n",
    "                for cluster in merge_results['Groups'][str(merge_number-1)][pointer]:\n",
    "                    group.append(cluster)\n",
    "            merge_results['Groups'][str(merge_number)].append(group)\n",
    "            # merge the clusters' dataframes to one and add it\n",
    "            merge_results['DataFrames'][str(merge_number)].append(pd.concat(dfs, sort=True))\n",
    "        merge_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['0', '1', '2'], dtype='object')\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(merge_results['Indexes'].index)\n",
    "print(merge_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2280\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for group in merge_results['Groups']['1']:\n",
    "    count += len(group)\n",
    "print(count)\n",
    "print(len(merge_results['Groups']['1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "22\n",
      "22\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "while len(merge_results['Groups'][str(merge_number - 1)]) > max_cluster_count:\n",
    "    # distance matrix generation\n",
    "    length = len(merge_results['Groups'][str(merge_number - 1)])\n",
    "    targets = list()\n",
    "    # dress the clusters for better distance performance\n",
    "    for i, group in enumerate(merge_results['Groups'][str(merge_number - 1)]):\n",
    "        # only select the distance relevant slice of the Dataframe\n",
    "        target = merge_results['DataFrames'][str(merge_number - 1)][i].groupby(['time_on_sale']).mean()[clustering_feature]\n",
    "        if (len(target) < 26):\n",
    "            # fill with 0 until index 25 so all comparison arrays are the same length\n",
    "            # this improves performance dramatically\n",
    "            target = target.reindex(pd.RangeIndex(26)).fillna(0)\n",
    "        targets.append(target)\n",
    "    distances = get_distance_matrix(targets)\n",
    "    clean = merge_all(distances)\n",
    "    merge_results['Indexes'][str(merge_number)] = clean\n",
    "    merge_results['Groups'][str(merge_number)] = list()\n",
    "    merge_results['DataFrames'][str(merge_number)] = list()\n",
    "    for i, pointers in enumerate(merge_results['Indexes'][str(merge_number)]):\n",
    "        group = list()\n",
    "        dfs = list()\n",
    "        for pointer in pointers:\n",
    "            df_temp = merge_results['DataFrames'][str(merge_number-1)][pointer]\n",
    "            dfs.append(df_temp)\n",
    "            for cluster in merge_results['Groups'][str(merge_number-1)][pointer]:\n",
    "                group.append(cluster)\n",
    "        merge_results['Groups'][str(merge_number)].append(group)\n",
    "        # merge the clusters' dataframes to one and add it\n",
    "        merge_results['DataFrames'][str(merge_number)].append(pd.concat(dfs, sort=True))\n",
    "    merge_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['0', '1', '2', '3', '4'], dtype='object')\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(merge_results['Indexes'].index)\n",
    "print(merge_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2280\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for group in merge_results['Groups']['3']:\n",
    "    count += len(group)\n",
    "print(count)\n",
    "print(len(merge_results['Groups']['3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Abteilung003: 27\n",
      "0: Abteilung005: 301\n",
      "0: Abteilung002: 2514\n",
      "0: Abteilung006: 1401\n",
      "0: Abteilung001: 172\n",
      "0: Abteilung007: 681\n",
      "0: Abteilung004: 229\n",
      "0: WHG017: 19\n",
      "0: WHG016: 8\n",
      "0: WHG018: 22\n",
      "0: WHG021: 131\n",
      "0: WHG010: 342\n",
      "0: WHG008: 47\n",
      "0: WHG012: 407\n",
      "0: WHG015: 645\n",
      "0: WHG007: 465\n",
      "0: WHG034: 457\n",
      "0: WHG003: 45\n",
      "0: WHG004: 9\n",
      "0: WHG009: 257\n",
      "0: WHG042: 218\n",
      "0: WHG043: 178\n",
      "0: WHG001: 77\n",
      "0: WHG013: 15\n",
      "0: WHG019: 28\n",
      "0: WHG022: 36\n",
      "0: WHG041: 285\n",
      "0: WHG006: 193\n",
      "0: WHG005: 94\n",
      "0: WHG030: 25\n",
      "0: WHG023: 40\n",
      "0: WHG031: 32\n",
      "0: WHG014: 35\n",
      "0: WHG038: 252\n",
      "0: WHG020: 44\n",
      "0: WHG011: 5\n",
      "0: WHG035: 188\n",
      "0: WHG032: 200\n",
      "0: WHG036: 132\n",
      "0: WHG028: 112\n",
      "0: WHG027: 42\n",
      "0: WHG002: 50\n",
      "0: WHG029: 4\n",
      "0: WHG026: 71\n",
      "0: WHG033: 48\n",
      "0: WHG037: 67\n",
      "0: WUG058: 19\n",
      "0: WUG057: 8\n",
      "0: WUG059: 11\n",
      "0: WUG060: 7\n",
      "0: WUG061: 4\n",
      "0: WUG073: 50\n",
      "0: WUG036: 29\n",
      "0: WUG034: 31\n",
      "0: WUG031: 34\n",
      "0: WUG023: 19\n",
      "0: WUG045: 137\n",
      "0: WUG053: 233\n",
      "0: WUG018: 83\n",
      "0: WUG020: 326\n",
      "0: WUG051: 232\n",
      "0: WUG117: 93\n",
      "0: WUG115: 113\n",
      "0: WUG114: 81\n",
      "0: WUG116: 75\n",
      "0: WUG006: 8\n",
      "0: WUG056: 48\n",
      "0: WUG052: 16\n",
      "0: WUG046: 61\n",
      "0: WUG054: 52\n",
      "0: WUG009: 3\n",
      "0: WUG032: 3\n",
      "0: WUG043: 17\n",
      "0: WUG030: 46\n",
      "0: WUG026: 7\n",
      "0: WUG055: 64\n",
      "0: WUG041: 18\n",
      "0: WUG139: 115\n",
      "0: WUG138: 103\n",
      "0: WUG029: 128\n",
      "0: WUG037: 54\n",
      "0: WUG146: 112\n",
      "0: WUG001: 77\n",
      "0: WUG048: 15\n",
      "0: WUG035: 56\n",
      "0: WUG069: 30\n",
      "0: WUG063: 14\n",
      "0: WUG079: 17\n",
      "0: WUG077: 8\n",
      "0: WUG078: 8\n",
      "0: WUG137: 94\n",
      "0: WUG136: 104\n",
      "0: WUG027: 28\n",
      "0: WUG015: 170\n",
      "0: WUG017: 19\n",
      "0: WUG011: 5\n",
      "0: WUG013: 38\n",
      "0: WUG033: 189\n",
      "0: WUG024: 1\n",
      "0: WUG104: 25\n",
      "0: WUG071: 10\n",
      "0: WUG086: 12\n",
      "0: WUG040: 156\n",
      "0: WUG042: 15\n",
      "0: WUG072: 40\n",
      "0: WUG076: 1\n",
      "0: WUG108: 32\n",
      "0: WUG049: 21\n",
      "0: WUG144: 34\n",
      "0: WUG084: 28\n",
      "0: WUG125: 34\n",
      "0: WUG067: 26\n",
      "0: WUG066: 18\n",
      "0: WUG021: 41\n",
      "0: WUG019: 15\n",
      "0: WUG028: 1\n",
      "0: WUG016: 4\n",
      "0: WUG022: 16\n",
      "0: WUG038: 4\n",
      "0: WUG014: 27\n",
      "0: WUG010: 23\n",
      "0: WUG143: 11\n",
      "0: WUG140: 87\n",
      "0: WUG132: 70\n",
      "0: WUG106: 24\n",
      "0: WUG107: 95\n",
      "0: WUG111: 38\n",
      "0: WUG130: 14\n",
      "0: WUG128: 25\n",
      "0: WUG129: 64\n",
      "0: WUG131: 44\n",
      "0: WUG119: 40\n",
      "0: WUG121: 34\n",
      "0: WUG112: 68\n",
      "0: WUG118: 77\n",
      "0: WUG105: 135\n",
      "0: WUG113: 23\n",
      "0: WUG109: 35\n",
      "0: WUG110: 36\n",
      "0: WUG005: 37\n",
      "0: WUG102: 39\n",
      "0: WUG100: 21\n",
      "0: WUG099: 49\n",
      "0: WUG103: 3\n",
      "0: WUG148: 5\n",
      "0: WUG149: 3\n",
      "0: WUG141: 3\n",
      "0: WUG097: 38\n",
      "0: WUG096: 2\n",
      "0: WUG095: 1\n",
      "0: WUG098: 1\n",
      "0: WUG074: 3\n",
      "0: WUG003: 50\n",
      "0: WUG101: 4\n",
      "0: WUG092: 16\n",
      "0: WUG093: 38\n",
      "0: WUG094: 14\n",
      "0: WUG091: 3\n",
      "0: WUG050: 14\n",
      "0: WUG007: 2\n",
      "0: WUG062: 14\n",
      "0: WUG008: 4\n",
      "0: WUG012: 1\n",
      "0: WUG025: 4\n",
      "0: WUG147: 5\n",
      "0: WUG145: 2\n",
      "0: WUG142: 3\n",
      "0: WUG123: 1\n",
      "0: WUG120: 47\n",
      "0: WUG127: 43\n",
      "0: WUG122: 4\n",
      "0: WUG124: 6\n",
      "0: WUG126: 24\n",
      "0: WUG133: 1\n",
      "0: WUG044: 3\n",
      "0: WUG039: 1\n",
      "0: Uller: 70\n",
      "0: Snotra: 19\n",
      "0: Baudihillia: 189\n",
      "0: Beda: 171\n",
      "0: Odin: 375\n",
      "0: Fulla: 63\n",
      "0: Gautr: 298\n",
      "0: Yngvi: 38\n",
      "0: Fimmilena: 366\n",
      "0: Mercurius Cimbrianus: 11\n",
      "0: Loki: 62\n",
      "0: Aumenahenae: 63\n",
      "0: Mani: 199\n",
      "0: Tuisto: 95\n",
      "0: Gna: 303\n",
      "0: Turstuahenae: 202\n",
      "0: Tyr: 180\n",
      "0: Freyr: 368\n",
      "0: Mercurius Arvernus: 299\n",
      "0: Aviaitinehae: 19\n",
      "0: Hel: 31\n",
      "0: Forseti: 5\n",
      "0: Travalaha: 132\n",
      "0: Hermodr: 4\n",
      "0: Heimdall: 64\n",
      "0: Burorina: 113\n",
      "0: Mercurius Hranno: 28\n",
      "0: Hercules Deusoniensis: 220\n",
      "0: Mahalinehae: 19\n",
      "0: Alaisiagae: 61\n",
      "0: Skuld: 3\n",
      "0: Friagabis: 238\n",
      "0: Almaviahenae: 3\n",
      "0: Gersimi: 250\n",
      "0: Nersihenae: 162\n",
      "0: Sif: 2\n",
      "0: Lodur: 142\n",
      "0: Kolga: 128\n",
      "0: Börr: 45\n",
      "0: Hödur: 1\n",
      "0: Hymir: 12\n",
      "0: Sigyn: 32\n",
      "0: Gebrinius: 33\n",
      "0: Þorgerðr Holgabrúðr: 21\n",
      "0: Vacallinehae: 23\n",
      "0: Grusduahenae: 17\n",
      "0: Gausus: 3\n",
      "0: Verdandi: 26\n",
      "0: Mars Halamardus: 2\n",
      "0: Mannus: 44\n",
      "0: Skadi: 36\n",
      "0: Aufaniae: 2\n",
      "0: Tamfana: 2\n",
      "0: Vagdavercustis: 2\n",
      "0: Hurstrga: 10\n",
      "0: Dag: 2\n",
      "0: Baduhenna: 14\n",
      "0: Axsinginehae: 3\n",
      "0: schwarz: 1105\n",
      "0: dunkelblau: 596\n",
      "0: schwarz / kombiniert: 389\n",
      "0: hellgrün: 18\n",
      "0: lila: 54\n",
      "0: mittelgrau: 337\n",
      "0: rosa: 145\n",
      "0: pink: 145\n",
      "0: mittelblau: 234\n",
      "0: rot: 63\n",
      "0: beige / kombiniert: 66\n",
      "0: gelb: 18\n",
      "0: bordeauxrot: 79\n",
      "0: hellbraun: 48\n",
      "0: dunkelgrau: 246\n",
      "0: dunkelbraun: 209\n",
      "0: mittelbraun: 372\n",
      "0: hellgrau: 166\n",
      "0: weiss: 100\n",
      "0: beige: 214\n",
      "0: weiss / kombiniert: 123\n",
      "0: graublau: 24\n",
      "0: camel: 80\n",
      "0: olivegrün: 27\n",
      "0: türkis: 51\n",
      "0: flieder: 19\n",
      "0: mintgrün: 19\n",
      "0: offwhite: 50\n",
      "0: khaki: 29\n",
      "0: weiss / schwarz: 11\n",
      "0: silber: 65\n",
      "0: gold: 48\n",
      "0: bronze/kupfer: 17\n",
      "0: grün: 15\n",
      "0: weiss / blau: 10\n",
      "0: hellblau: 56\n",
      "0: rost: 2\n",
      "0: multicolor: 57\n",
      "0: orange: 17\n",
      "0: ockergelb: 1\n",
      "0: Jan: 1825\n",
      "0: Feb: 2197\n",
      "0: Mar: 2755\n",
      "0: Apr: 2643\n",
      "0: May: 2709\n",
      "0: Jun: 2537\n",
      "0: Jul: 2412\n",
      "0: Aug: 2683\n",
      "0: Sep: 2467\n",
      "0: Oct: 2104\n",
      "0: Nov: 1762\n",
      "0: Dec: 1609\n",
      "0: Winter: 1587\n",
      "0: Spring: 1554\n",
      "0: Summer: 1309\n",
      "0: Fall: 875\n",
      "\n",
      "1: Abteilung005: 1159\n",
      "1: Abteilung002: 2016\n",
      "1: Abteilung006: 1480\n",
      "1: Abteilung007: 791\n",
      "1: Abteilung001: 26\n",
      "1: Abteilung004: 35\n",
      "1: WHG024: 5\n",
      "1: WHG015: 380\n",
      "1: WHG010: 286\n",
      "1: WHG007: 368\n",
      "1: WHG011: 15\n",
      "1: WHG014: 44\n",
      "1: WHG009: 342\n",
      "1: WHG012: 263\n",
      "1: WHG034: 511\n",
      "1: WHG035: 197\n",
      "1: WHG038: 268\n",
      "1: WHG032: 198\n",
      "1: WHG039: 48\n",
      "1: WHG022: 239\n",
      "1: WHG006: 124\n",
      "1: WHG041: 317\n",
      "1: WHG021: 641\n",
      "1: WHG043: 140\n",
      "1: WHG023: 190\n",
      "1: WHG001: 25\n",
      "1: WHG013: 24\n",
      "1: WHG005: 64\n",
      "1: WHG019: 24\n",
      "1: WHG008: 105\n",
      "1: WHG031: 32\n",
      "1: WHG030: 25\n",
      "1: WHG042: 258\n",
      "1: WHG026: 21\n",
      "1: WHG028: 14\n",
      "1: WHG025: 52\n",
      "1: WHG033: 48\n",
      "1: WHG037: 68\n",
      "1: WHG040: 28\n",
      "1: WHG036: 133\n",
      "1: WHG002: 1\n",
      "1: WHG020: 8\n",
      "1: WHG004: 1\n",
      "1: WUG087: 5\n",
      "1: WUG053: 183\n",
      "1: WUG031: 18\n",
      "1: WUG018: 114\n",
      "1: WUG051: 121\n",
      "1: WUG038: 15\n",
      "1: WUG049: 37\n",
      "1: WUG029: 233\n",
      "1: WUG033: 194\n",
      "1: WUG040: 83\n",
      "1: WUG037: 56\n",
      "1: WUG045: 84\n",
      "1: WUG114: 92\n",
      "1: WUG105: 135\n",
      "1: WUG115: 138\n",
      "1: WUG116: 79\n",
      "1: WUG129: 69\n",
      "1: WUG112: 72\n",
      "1: WUG020: 233\n",
      "1: WUG107: 101\n",
      "1: WUG152: 16\n",
      "1: WUG151: 23\n",
      "1: WUG150: 9\n",
      "1: WUG077: 100\n",
      "1: WUG074: 60\n",
      "1: WUG078: 39\n",
      "1: WUG079: 23\n",
      "1: WUG015: 106\n",
      "1: WUG140: 94\n",
      "1: WUG136: 135\n",
      "1: WUG137: 88\n",
      "1: WUG042: 38\n",
      "1: WUG069: 151\n",
      "1: WUG149: 16\n",
      "1: WUG085: 14\n",
      "1: WUG002: 6\n",
      "1: WUG048: 22\n",
      "1: WUG013: 52\n",
      "1: WUG064: 21\n",
      "1: WUG001: 19\n",
      "1: WUG023: 56\n",
      "1: WUG017: 3\n",
      "1: WUG108: 32\n",
      "1: WUG104: 25\n",
      "1: WUG071: 29\n",
      "1: WUG072: 118\n",
      "1: WUG086: 63\n",
      "1: WUG138: 118\n",
      "1: WUG139: 140\n",
      "1: WUG073: 183\n",
      "1: WUG093: 19\n",
      "1: WUG102: 5\n",
      "1: WUG099: 5\n",
      "1: WUG070: 85\n",
      "1: WUG076: 30\n",
      "1: WUG027: 43\n",
      "1: WUG144: 16\n",
      "1: WUG141: 9\n",
      "1: WUG146: 66\n",
      "1: WUG143: 9\n",
      "1: WUG035: 69\n",
      "1: WUG083: 8\n",
      "1: WUG090: 11\n",
      "1: WUG089: 21\n",
      "1: WUG088: 19\n",
      "1: WUG075: 1\n",
      "1: WUG055: 51\n",
      "1: WUG050: 7\n",
      "1: WUG081: 84\n",
      "1: WUG022: 27\n",
      "1: WUG025: 18\n",
      "1: WUG147: 4\n",
      "1: WUG080: 17\n",
      "1: WUG082: 21\n",
      "1: WUG016: 15\n",
      "1: WUG068: 45\n",
      "1: WUG044: 3\n",
      "1: WUG145: 17\n",
      "1: WUG130: 15\n",
      "1: WUG128: 25\n",
      "1: WUG132: 80\n",
      "1: WUG125: 34\n",
      "1: WUG106: 24\n",
      "1: WUG118: 86\n",
      "1: WUG131: 44\n",
      "1: WUG117: 101\n",
      "1: WUG011: 5\n",
      "1: WUG111: 38\n",
      "1: WUG109: 32\n",
      "1: WUG127: 44\n",
      "1: WUG126: 24\n",
      "1: WUG134: 12\n",
      "1: WUG135: 16\n",
      "1: WUG021: 16\n",
      "1: WUG046: 40\n",
      "1: WUG014: 7\n",
      "1: WUG019: 5\n",
      "1: WUG030: 10\n",
      "1: WUG052: 7\n",
      "1: WUG054: 14\n",
      "1: WUG056: 4\n",
      "1: WUG148: 3\n",
      "1: WUG119: 41\n",
      "1: WUG120: 47\n",
      "1: WUG121: 34\n",
      "1: WUG122: 4\n",
      "1: WUG113: 23\n",
      "1: WUG110: 33\n",
      "1: WUG133: 1\n",
      "1: WUG004: 1\n",
      "1: WUG067: 5\n",
      "1: WUG066: 3\n",
      "1: WUG124: 6\n",
      "1: WUG043: 3\n",
      "1: WUG041: 12\n",
      "1: WUG036: 2\n",
      "1: WUG047: 2\n",
      "1: WUG065: 3\n",
      "1: WUG009: 1\n",
      "1: WUG094: 2\n",
      "1: WUG103: 4\n",
      "1: WUG024: 1\n",
      "1: WUG034: 3\n",
      "1: WUG026: 3\n",
      "1: WUG123: 1\n",
      "1: Hermodr: 26\n",
      "1: Fimmilena: 224\n",
      "1: Lodur: 198\n",
      "1: Alaisiagae: 256\n",
      "1: Freyr: 357\n",
      "1: Baduhenna: 15\n",
      "1: Travalaha: 249\n",
      "1: Gebrinius: 33\n",
      "1: Gausus: 3\n",
      "1: Baudihillia: 106\n",
      "1: Odin: 181\n",
      "1: Mercurius Arvernus: 274\n",
      "1: Beda: 170\n",
      "1: Turstuahenae: 132\n",
      "1: Aviaitinehae: 14\n",
      "1: Þorgerðr Holgabrúðr: 22\n",
      "1: Burorina: 130\n",
      "1: Almaviahenae: 125\n",
      "1: Loki: 100\n",
      "1: Siofna: 99\n",
      "1: Snotra: 229\n",
      "1: Hel: 21\n",
      "1: Uller: 33\n",
      "1: Hymir: 128\n",
      "1: Tuisto: 76\n",
      "1: Gna: 304\n",
      "1: Gersimi: 80\n",
      "1: Mahalinehae: 22\n",
      "1: Mercurius Hranno: 91\n",
      "1: Hödur: 8\n",
      "1: Gautr: 91\n",
      "1: Nersihenae: 36\n",
      "1: Mani: 110\n",
      "1: Fulla: 32\n",
      "1: Heimdall: 254\n",
      "1: Tyr: 127\n",
      "1: Sunuxsal: 12\n",
      "1: Thor: 5\n",
      "1: Alaferhviae: 100\n",
      "1: Skuld: 83\n",
      "1: Friagabis: 433\n",
      "1: Forseti: 15\n",
      "1: Mercurius Cimbrianus: 54\n",
      "1: Aumenahenae: 2\n",
      "1: Freya: 42\n",
      "1: Sigyn: 34\n",
      "1: Kolga: 122\n",
      "1: Grusduahenae: 17\n",
      "1: Börr: 7\n",
      "1: Vacallinehae: 24\n",
      "1: Axsinginehae: 5\n",
      "1: Verdandi: 2\n",
      "1: Nornen: 30\n",
      "1: Wanen: 44\n",
      "1: Gratichae: 18\n",
      "1: Mars Halamardus: 1\n",
      "1: Idun: 19\n",
      "1: Hariasa: 2\n",
      "1: Hludana: 16\n",
      "1: Abiamarcae: 30\n",
      "1: Vili: 7\n",
      "1: Sif: 4\n",
      "1: Alaterviae: 5\n",
      "1: Ahinehiae: 5\n",
      "1: Dise: 6\n",
      "1: Surt: 7\n",
      "1: dunkelgrau: 316\n",
      "1: schwarz: 1013\n",
      "1: mittelbraun: 439\n",
      "1: offwhite: 41\n",
      "1: beige: 190\n",
      "1: hellblau: 50\n",
      "1: dunkelblau: 628\n",
      "1: orange: 24\n",
      "1: mittelgrau: 361\n",
      "1: mittelblau: 229\n",
      "1: grün: 12\n",
      "1: schwarz / kombiniert: 408\n",
      "1: rosa: 150\n",
      "1: bordeauxrot: 90\n",
      "1: hellbraun: 86\n",
      "1: beige / kombiniert: 58\n",
      "1: weiss / kombiniert: 98\n",
      "1: silber: 55\n",
      "1: türkis: 52\n",
      "1: lila: 47\n",
      "1: khaki: 36\n",
      "1: dunkelbraun: 369\n",
      "1: pink: 121\n",
      "1: multicolor: 32\n",
      "1: hellgrau: 154\n",
      "1: graublau: 31\n",
      "1: weiss / blau: 6\n",
      "1: olivegrün: 38\n",
      "1: camel: 74\n",
      "1: rot: 49\n",
      "1: weiss: 93\n",
      "1: bronze/kupfer: 17\n",
      "1: weiss / schwarz: 9\n",
      "1: gold: 41\n",
      "1: gelb: 25\n",
      "1: hellgrün: 14\n",
      "1: mintgrün: 23\n",
      "1: rost: 10\n",
      "1: flieder: 17\n",
      "1: ockergelb: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Nov: 2255\n",
      "1: Dec: 2422\n",
      "1: Jan: 2985\n",
      "1: Feb: 3082\n",
      "1: Mar: 2492\n",
      "1: Oct: 2164\n",
      "1: Apr: 1974\n",
      "1: May: 2038\n",
      "1: Jun: 2391\n",
      "1: Aug: 3129\n",
      "1: Sep: 2991\n",
      "1: Jul: 3080\n",
      "1: Fall: 1219\n",
      "1: Spring: 1478\n",
      "1: Winter: 1359\n",
      "1: Summer: 1451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(merge_results['DataFrames']['4']):\n",
    "    for col in df.select_dtypes(include=['category']):\n",
    "        # print(str(i) + \": \" + str(col) + \": \" + str(df[col].unique()))\n",
    "        if \"article_id\" not in col:\n",
    "            for characteristic in df[col].unique():\n",
    "                query_string = str(col) + \" == \" + '\"' + str(characteristic) + '\"'\n",
    "                temp_df = df.query(query_string)\n",
    "                print(str(i) + \": \" + str(characteristic) + \": \" + str(temp_df['article_id'].nunique()))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tailor",
   "language": "python",
   "name": "tailor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
